{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Augmentation.ipynb","provenance":[],"authorship_tag":"ABX9TyPI1wPlBGYyZHH1/eLI+Eqb"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"l2XtHIIWzcR3","executionInfo":{"status":"ok","timestamp":1652288272441,"user_tz":240,"elapsed":2089,"user":{"displayName":"Jai Ramesh Puro","userId":"11869615647144949437"}},"outputId":"f6417fb4-bb8f-4912-faef-303fd8143b95"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["import sys\n","sys.path.append('/content/drive/My Drive/685/Sentence-Simplification-using-BERT-GPT2/')\n","%cd '/content/drive/My Drive/685/Sentence-Simplification-using-BERT-GPT2/'"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"udpJ0sex1OmJ","executionInfo":{"status":"ok","timestamp":1652288274374,"user_tz":240,"elapsed":964,"user":{"displayName":"Jai Ramesh Puro","userId":"11869615647144949437"}},"outputId":"46141001-1bb6-4acf-9f3b-01b5f5357f59"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/My Drive/685/Sentence-Simplification-using-BERT-GPT2\n"]}]},{"cell_type":"code","source":["!pip install -q transformers==4.17.0 datasets==2.0.0 rich[jupyter]\n","!pip install -q googletrans==3.1.0a0\n","!pip install -q -U PyDrive\n","\n","from pydrive.auth import GoogleAuth\n","from pydrive.drive import GoogleDrive\n","from google.colab import auth\n","from oauth2client.client import GoogleCredentials\n","# Authenticate and create the PyDrive client.\n","auth.authenticate_user()\n","gauth = GoogleAuth()\n","gauth.credentials = GoogleCredentials.get_application_default()\n","drive = GoogleDrive(gauth)\n","print('success!')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0L4MpZQ82t50","executionInfo":{"status":"ok","timestamp":1652293017191,"user_tz":240,"elapsed":62979,"user":{"displayName":"Jai Ramesh Puro","userId":"11869615647144949437"}},"outputId":"90f63c25-5da3-46f6-9519-27f7276e66eb"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[K     |████████████████████████████████| 3.8 MB 5.2 MB/s \n","\u001b[K     |████████████████████████████████| 325 kB 46.8 MB/s \n","\u001b[K     |████████████████████████████████| 231 kB 52.9 MB/s \n","\u001b[K     |████████████████████████████████| 1.1 MB 42.1 MB/s \n","\u001b[K     |████████████████████████████████| 212 kB 46.9 MB/s \n","\u001b[K     |████████████████████████████████| 136 kB 54.5 MB/s \n","\u001b[K     |████████████████████████████████| 127 kB 5.0 MB/s \n","\u001b[K     |████████████████████████████████| 271 kB 51.6 MB/s \n","\u001b[K     |████████████████████████████████| 144 kB 63.1 MB/s \n","\u001b[K     |████████████████████████████████| 94 kB 2.0 MB/s \n","\u001b[K     |████████████████████████████████| 51 kB 2.4 MB/s \n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n","\u001b[?25h  Building wheel for googletrans (setup.py) ... \u001b[?25l\u001b[?25hdone\n","success!\n"]}]},{"cell_type":"code","source":["import googletrans\n","#print(googletrans.LANGUAGES)\n","from googletrans import Translator\n","translator = translator = Translator()"],"metadata":{"id":"ugriLZAaQoj5","executionInfo":{"status":"ok","timestamp":1652293020445,"user_tz":240,"elapsed":98,"user":{"displayName":"Jai Ramesh Puro","userId":"11869615647144949437"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["import string\n","translate_table = dict((ord(char), None) for char in string.punctuation)   \n","\n","NUM_EXAMPLES = 100\n","train_examples = []\n","file_path = 'dataset/src_train.txt'\n","\n","with open(file_path, 'r', encoding=\"utf8\") as f:\n","    sents = [next(f) for x in range(NUM_EXAMPLES)]\n","    for s in sents:\n","        train_examples.append(s.strip().translate(translate_table))"],"metadata":{"id":"4yiOykW-QhXf","executionInfo":{"status":"ok","timestamp":1652293023343,"user_tz":240,"elapsed":109,"user":{"displayName":"Jai Ramesh Puro","userId":"11869615647144949437"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["train_examples_augmented = []\n","\n","for example in train_examples:\n","    train_examples_augmented.append(example) # always include the original example\n","    latin_languages = ['de', 'fr', 'it', 'es','pt']\n","    #nonlatin_languages = ['hi', 'cs', 'ja', 'zh-cn', 'vi']\n","    for target_language in latin_languages:\n","      translated = translator.translate('hi i am long',src='en', dest=target_language)\n","      paraphrase = translator.translate(translated.text, src=target_language, dest='en')\n","      # the below line adds a single new augmented example to the dataset. \n","      # note that the guid should be a unique ID for this example, so you'll want to vary this\n","      # depending on how you generate your paraphrases\n","      train_examples_augmented.append(paraphrase.text)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":389},"id":"4I3rDvaeQkKH","executionInfo":{"status":"error","timestamp":1652293026121,"user_tz":240,"elapsed":434,"user":{"displayName":"Jai Ramesh Puro","userId":"11869615647144949437"}},"outputId":"2ab5d30f-52ce-4381-e272-d7df185bbe32"},"execution_count":14,"outputs":[{"output_type":"error","ename":"AttributeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-14-3cfbd2354724>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m#nonlatin_languages = ['hi', 'cs', 'ja', 'zh-cn', 'vi']\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mtarget_language\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlatin_languages\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m       \u001b[0mtranslated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtranslator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranslate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'hi i am long'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'en'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget_language\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m       \u001b[0mparaphrase\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtranslator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranslate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtranslated\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget_language\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'en'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m       \u001b[0;31m# the below line adds a single new augmented example to the dataset.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/googletrans/client.py\u001b[0m in \u001b[0;36mtranslate\u001b[0;34m(self, text, dest, src, **kwargs)\u001b[0m\n\u001b[1;32m    180\u001b[0m             \u001b[0mjumps\u001b[0m \u001b[0mover\u001b[0m  \u001b[0;34m->\u001b[0m  \u001b[0m이상\u001b[0m \u001b[0m점프\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m             \u001b[0mthe\u001b[0m \u001b[0mlazy\u001b[0m \u001b[0mdog\u001b[0m  \u001b[0;34m->\u001b[0m  \u001b[0m게으른\u001b[0m \u001b[0m개\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         \"\"\"\n\u001b[0m\u001b[1;32m    183\u001b[0m         \u001b[0mdest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'_'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \u001b[0msrc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'_'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/googletrans/client.py\u001b[0m in \u001b[0;36m_translate\u001b[0;34m(self, text, dest, src, override)\u001b[0m\n\u001b[1;32m     76\u001b[0m             self.token_acquirer = TokenAcquirer(\n\u001b[1;32m     77\u001b[0m                 client=self.client, host=self.service_urls[0])\n\u001b[0;32m---> 78\u001b[0;31m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m             \u001b[0;31m#if we have a service url pointing to client api we force the use of it as defaut client\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mservice_urls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/googletrans/gtoken.py\u001b[0m in \u001b[0;36mdo\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    192\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pragma: nocover\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m             \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;36m2147483647\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m2147483648\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 194\u001b[0;31m         \u001b[0ma\u001b[0m \u001b[0;34m%=\u001b[0m \u001b[0;36m1000000\u001b[0m  \u001b[0;31m# int(1E6)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m'{}.{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m^\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/googletrans/gtoken.py\u001b[0m in \u001b[0;36m_update\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m             \u001b[0;31m# this will be the same as python code after stripping out a reserved word 'var'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m             \u001b[0mcode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRE_TKK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'var '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m             \u001b[0;31m# unescape special ascii characters such like a \\x3d(=)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'group'"]}]},{"cell_type":"code","source":["data_dir = '/dataset'\n","task_processor = glue_processors[f\"{task_name.lower()}-2\"]()\n","train_examples = task_processor.get_train_examples(data_dir)\n","\n","train_examples_augmented = []\n","\n","### (incomplete) list of languages you can use\n","languages = [\n","    'en', # english\n","    'cs',  # czech\n","    'de',  # german\n","    'es', # spanish\n","    'fi',  # finnish\n","    'fr', # french\n","    'hi', # hindi\n","    'it', # italian\n","    'ja', # japanese\n","    'pt', # portuguese\n","    'ru', # russian\n","    'vi', # vietnamese\n","    'zh-cn',  # chinese\n","    ]\n","\n","# generate some augmented examples for each training example\n","for example in train_examples:\n","    train_examples_augmented.append(example) # always include the original example\n","    latin_languages = ['de', 'fr', 'it', 'es','pt']\n","    #nonlatin_languages = ['hi', 'cs', 'ja', 'zh-cn', 'vi']\n","    for target_language in latin_languages:\n","      translated = translator.translate(example.text_a, src='en', dest=target_language)\n","      paraphrase = translator.translate(translated.text, src=target_language, dest='en')\n","      # the below line adds a single new augmented example to the dataset. \n","      # note that the guid should be a unique ID for this example, so you'll want to vary this\n","      # depending on how you generate your paraphrases\n","      train_examples_augmented.append(InputExample(guid=f\"{example.guid}-aug-{target_language}\",\n","                                                      text_a=paraphrase.text,\n","                                                      text_b=None,\n","                                                      label=example.label))\n","output_dir = f\"./data/tiny{task_name}-bt\"\n","if not os.path.exists(output_dir):\n","    os.makedirs(output_dir)\n","    \n","with open(os.path.join(output_dir, \"train.tsv\"), \"w\") as writer:\n","    writer.write(\"sentence\\tlabel\\n\")\n","    for example in train_examples_augmented:\n","        writer.write(f\"{example.text_a}\\t{example.label}\\n\")\n","tsv_to_csv(os.path.join(output_dir, \"train.tsv\"), os.path.join(output_dir, \"train.csv\"))\n","\n","# Copy the original tinySST's dev set to the new directory\n","import shutil\n","shutil.copyfile(f\"{data_dir}/dev.csv\", f\"{output_dir}/dev.csv\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":240},"id":"FGdX9QC8D388","executionInfo":{"status":"error","timestamp":1652291646519,"user_tz":240,"elapsed":310,"user":{"displayName":"Jai Ramesh Puro","userId":"11869615647144949437"}},"outputId":"2a2994e0-c17f-4cf6-f8b6-c96d66b3153f"},"execution_count":6,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-6-1e8452e23eb1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdata_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/dataset'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtask_processor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mglue_processors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34mf\"{task_name.lower()}-2\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtrain_examples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtask_processor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_train_examples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtrain_examples_augmented\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'glue_processors' is not defined"]}]}]}